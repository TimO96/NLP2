{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from senreps import proc_embeddings, proc_embeddings_bertje\n",
    "from torch import Tensor\n",
    "from transformers import *\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "'''\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True).to(device=device)\n",
    "task = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "'''\n",
    "model = BertModel.from_pretrained('bert-base-dutch-cased', output_hidden_states=True).to(device=device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-dutch-cased')\n",
    "task = BertForMaskedLM.from_pretrained('bert-base-dutch-cased').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from polyglot.mapping import Embedding\n",
    "from polyglot.downloader import downloader\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nl_en = {}\n",
    "\n",
    "embeddings = Embedding.load(\"embeddings2/nl/embeddings_pkl.tar.bz2\")\n",
    "\n",
    "with open('data/filtered_en_nl_dict.txt', 'r') as bidict:\n",
    "    for trans in bidict:\n",
    "        nl, en = trans.split()\n",
    "        nl_en[nl] = en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(path):\n",
    "    proc_data = []\n",
    "    with open(path, 'r') as data: \n",
    "        for sentence in data:\n",
    "            proc_sentence = word_tokenize(sentence.lower())\n",
    "            proc_data.append(proc_sentence)\n",
    "    \n",
    "    return proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['biologie', 'is', 'de', 'natuurwetenschap', 'die', 'zich', 'richt', 'op', 'levende', 'organismen', ',', 'levensprocessen', 'en', 'levensverschijnselen', '.'], ['de', 'biologie', 'omvat', 'een', 'breed', 'scala', 'aan', 'vakgebieden', 'waarin', 'men', 'onderzoek', 'doet', 'naar', 'fysieke', 'structuur', ',', 'chemische', 'processen', ',', 'moleculaire', 'interacties', ',', 'fysiologische', 'mechanismen', ',', 'ecologische', 'dynamiek', ',', 'ontwikkeling', 'en', 'evolutie', '.'], ['biologie', 'erkent', 'de', 'cel', 'als', 'de', 'fysieke', 'basiseenheid', 'van', 'het', 'leven', ',', 'genen', 'als', 'de', 'basiseenheid', 'van', 'erfelijke', 'informatie', 'en', 'evolutie', 'als', 'de', 'drijvende', 'kracht', 'achter', 'het', 'ontstaan', 'en', 'het', 'uitsterven', 'van', 'soorten', '.'], ['levende', 'organismen', 'zijn', 'open', 'systemen', 'die', 'in', 'staat', 'zijn', 'te', 'overleven', 'door', 'bruikbare', 'omzettingen', 'van', 'energie', 'en', 'door', 'handhaving', 'van', 'hun', 'vitale', 'toestand', '.'], ['omdat', 'moderne', 'biologie', 'overwegend', 'een', 'exacte', 'natuurwetenschap', 'is', ',', 'domineren', 'experimentele', ',', 'kwantitatieve', 'benaderingen', 'en', 'causale', 'verklaringen', '.']]\n"
     ]
    }
   ],
   "source": [
    "train_data = preprocess_data('data/train.txt')\n",
    "dev_data = preprocess_data('data/valid.txt')\n",
    "test_data = preprocess_data('data/test.txt')\n",
    "print(train_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [27:57<00:00, 47.68it/s]\n",
      "100%|██████████| 10000/10000 [03:37<00:00, 46.01it/s]\n",
      "100%|██████████| 10000/10000 [03:37<00:00, 45.96it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {'train':[], 'dev':[], 'test':[]}\n",
    "\n",
    "data['train'] = proc_embeddings_bertje(train_data, model, tokenizer, embeddings, nl_en, 'TF', device)\n",
    "data['dev'] = proc_embeddings_bertje(dev_data, model, tokenizer, embeddings, nl_en, 'TF', device)\n",
    "data['test'] = proc_embeddings_bertje(test_data, model, tokenizer, embeddings, nl_en, 'TF', device)\n",
    "\n",
    "torch.save(data, 'xlingual_data_dutch.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "W = train(data, epochs=100, batch_size=64, lr=1e-4, early_stopping=True)\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(W, 'proj_matrix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = Tensor([tokenizer.encode('I want to [MASK] the bike because it is cheap')]).type(torch.long).to(device)\n",
    "input_embs = model(input_ids)[-1][0]\n",
    "mask_embs = model(Tensor([103]).unsqueeze(0).type(torch.long).to(device))[-1][0]\n",
    "print(masked_labels.size())\n",
    "output1 = task(inputs_embeds=input_embs)\n",
    "output2 = task(input_ids)\n",
    "\n",
    "print(output1.size())\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = Tensor([0, 2]).type(torch.long)\n",
    "predicted_token = torch.argmax(output1[0][indices])\n",
    "\n",
    "print(predicted_token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
